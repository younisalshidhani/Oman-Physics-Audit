import re
import json
from io import BytesIO
from typing import List, Dict, Tuple

import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai

from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT

try:
    from PIL import Image
except Exception:
    Image = None


# =========================
# ูุงุฌูุฉ
# =========================
st.set_page_config(page_title="ูุธุงู ุชุฏููู ุงูุงุฎุชุจุงุฑุงุช - ุณูุทูุฉ ุนูุงู", layout="wide")

st.markdown(
    """
    <style>
    .stApp { direction: rtl; text-align: right; }
    div[data-testid="stSidebar"] { text-align: right; direction: rtl; }
    div[data-testid="stMarkdownContainer"] { text-align: right; direction: rtl; }

    .report-box { border: 2px solid #007bff; padding: 14px; border-radius: 10px; background-color: #f9f9f9; }
    .tbl { width:100%; border-collapse:collapse; direction:rtl; }
    .tbl th, .tbl td { border:1px solid #ddd; padding:8px; vertical-align:top; text-align:right; }
    .tbl th { background:#f1f1f1; font-weight:700; }
    .muted { color:#666; font-size: 13px; }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("๐ ูุธุงู ุชุฏููู ุงูุงุฎุชุจุงุฑุงุช (ูุทุงุจูุฉ ุงูุจููุฏ ูุงููุนุงููุฑ)")
st.caption("ูุฑูุน: ุงูุงุฎุชุจุงุฑ + ูุซููุฉ ุงูุชูููู + ูุชุงุจ ุงูุทุงูุจุ ุซู ูุนุฑุถ ุงูุชูุฑูุฑ ุฏุงุฎู ุงูุตูุญุฉ ููู ูููุฐุฌูุ ูุน ุฎูุงุฑ ุชูุฒูู Word.")


# =========================
# ุฅุนุฏุงุฏุงุช ุฌุงูุจูุฉ
# =========================
st.sidebar.header("โ๏ธ ุฅุนุฏุงุฏุงุช ุงูุชุฏููู")
api_key = st.sidebar.text_input("ููุชุงุญ API (Gemini):", type="password")

subject = st.sidebar.selectbox("ุงููุงุฏุฉ:", ["ููุฒูุงุก", "ููููุงุก", "ุฃุญูุงุก", "ุนููู"], index=0)
semester = st.sidebar.selectbox("ุงููุตู ุงูุฏุฑุงุณู:", ["ุงูุฃูู", "ุงูุซุงูู"], index=1)
grade = st.sidebar.selectbox("ุงูุตู:", ["11", "12"], index=1)
exam_type = st.sidebar.selectbox("ููุน ุงูุงุฎุชุจุงุฑ:", ["ูุตูุฑ", "ุงุณุชูุตุงุฆู"], index=0)
pages_range = st.sidebar.text_input("ูุทุงู ุงูุตูุญุงุช (ูุซุงู 77-97):", value="")


# =========================
# ุชุนุฑููุงุช ุฃูุฏุงู ุงูุชูููู ุงูุฑุณููุฉ (ุญุณุจ ูุซููุฉ ุงูุชูููู)
# =========================
A01_DEFINITION = """
ูุฏู ุงูุชูููู ุงูุฃูู (A01): ุงููุนุฑูุฉ ูุงูููู.
ูููุณ ุชุฐูุฑ ูููู ุงูููุฑุฏุงุช ูุงูููุงููู ูุงูุญูุงุฆู ุงูุนูููุฉ ูุงูุฅุฌุฑุงุกุงุช ุงููุฑุชุจุทุฉ ุจูุงุ ูุชูุณูุฑูุง ุฃู ุชูุถูุญูุง ุจุตูุฑุฉ ูุจุณุทุฉ.
ููุซู ุฐูู: ุงููุนุทูุงุช ูุงูุญูุงุฆู ูุงูููุงููู ูุงูุชุนุฑููุงุช ูุงูููุงููู ูุงููุธุฑูุงุช ุงูุนูููุฉุ ุงูุฑููุฒ ูุงููุญุฏุงุช ูุงูุตูุบ ูุงููุตุทูุญุงุช ุงูุนูููุฉุ
ุงุณุชุฎุฏุงู ุงูุฃุดูุงู ุงูุชุฎุทูุทูุฉ/ุงูุฑุณููุงุช ุงููุงุถุญุฉุ ุงูุธูุงูุฑ ูุงูุฃููุงุท ูุงูุนูุงูุงุชุ ุฎูุงุต ุงูููุงุฏุ ุงุณุชุฎุฏุงู ุงูุฃุฌูุฒุฉ ุงูุนูููุฉุ ุงููููุงุช ุงูุนูููุฉ ูููุงุณูุง.

ููุชุทูุจ ุจุนุถ ุงูููุงุฑุงุช ุงูุญุณุงุจูุฉ ูุซู:
- ุฅุฌุฑุงุก ุนูููุงุช ุญุณุงุจูุฉ ุฐุงุช ุงูุฎุทูุฉ ุงููุงุญุฏุฉ.
- ุฅุฌุฑุงุก ุชุนููุถ ุจุณูุท ููุฃุฑูุงู ูู ุตูุบุฉ ูุชู ุชุฐูุฑูุง ุฃู ุชูุฏูููุง.
- ุฅุนุงุฏุฉ ุชุฑุชูุจ ุจุณูุทุฉ/ูุนุงูุฌุฉ ุจุณูุทุฉ ููุตูุบ ุฃู ุงูุจูุงูุงุช ุฃู ุงูุฃุฑูุงู ุงููุญุฏุฏุฉ.
"""

A02_DEFINITION = """
ูุฏู ุงูุชูููู ุงูุซุงูู (A02): ุงูุชุทุจูู ูุงูุชุญููู ูุงูุชูููู.
ูุนุชูุฏ ุนูู ุงุฎุชุจุงุฑ ุงููุนูููุงุช ุบูุฑ ุงููุฃูููุฉ ูุฏู ุงูุทูุจุฉุ ุจูุง ูุชุทูุจ ุชุทุจูู ุงููุนุฑูุฉ ุจุทุฑููุฉ ููุทููุฉ ูุงุณุชูุชุงุฌูุฉุ
ูููุชููุน ุฃู ูุทูุจ ุชุญููู ุงูุจูุงูุงุช ูุญู ุงููุดููุงุช ุฃู ุชูููููุงุ ููุฏ ูุตู ููุณุชูู ุฃุนูู ูู ุงูุชูููุฑ ุงูููุฏู.

ููุซู ุฐูู: ุนุฑุถ/ุชูุณูุฑ ุงูุจูุงูุงุช ูู ุดูู ูุฑุฆู (ุฌุฏุงูู/ุฑุณููุงุช/ุตูุฑ/ูุฎุทุทุงุช/ุชูุซููุงุช ุจูุงููุฉ)ุ
ุฌูุน ูุชูุธูู ุงูุจูุงูุงุช ูุชูุฏูููุง ุจุตูุฑุฉ ุนูููุฉุ ุชุญุฏูุฏ ุงูุฃููุงุท ูุงูุงุชุฌุงูุงุช ูุงุณุชุฎูุงุต ุงููุชุงุฆุฌุ
ุฅุฌุฑุงุก ุชุญูููุงุช/ุชุฌุงุฑุจ ูุฏุนู ุงููุฑุถูุงุช ูุชูููู ุงููุนูููุงุชุ ุฑุจุท ุงููุนุฑูุฉ ุจุณูุงูุงุช ุบูุฑ ูุฃูููุฉุ
ุดุฑุญ ุงูุฃุญุฏุงุซ ูุงูุธูุงูุฑ ูุงูุฃููุงุท ูุงูุนูุงูุงุช ุชูุณูุฑูุง ุณุจุจููุงุ ุงุณุชุฎุฏุงู ุงููุฎุทุทุงุช/ุงูููุงุฐุฌ ูุฅุซุจุงุช ุงููููููุ
ุญุณุงุจ ููุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุนุฏุฏูุฉ (ุฎุตูุตูุง ูุชุนุฏุฏุฉ ุงูุฎุทูุงุช)ุ ุญู ุงููุดููุงุช.
"""

st.sidebar.markdown(
    """
<div class="muted">
<b>ุชุนุฑูู ุฑุณูู ูุฃูุฏุงู ุงูุชูููู:</b><br>
<b>A01</b>: ูุนุฑูุฉ ูููู + ุชูุถูุญ ูุจุณุท + (ุฎุทูุฉ ูุงุญุฏุฉ/ุชุนููุถ ุจุณูุท/ูุนุงูุฌุฉ ุจุณูุทุฉ).<br>
<b>A02</b>: ุชุทุจูู/ุชุญููู/ุชูููู + ุณูุงูุงุช ุบูุฑ ูุฃูููุฉ + ุจูุงูุงุช/ุฑุณูู/ุงุณุชูุชุงุฌ + (ูุชุนุฏุฏุฉ ุงูุฎุทูุงุช).<br>
</div>
""",
    unsafe_allow_html=True
)


# =========================
# ุฑูุน ุงููููุงุช
# =========================
col1, col2, col3 = st.columns(3)
with col1:
    file_test = st.file_uploader("1) ููู ุงูุงุฎุชุจุงุฑ (PDF)", type="pdf")
with col2:
    file_policy = st.file_uploader("2) ูุซููุฉ ุงูุชูููู (PDF)", type="pdf")
with col3:
    file_book = st.file_uploader("3) ูุชุงุจ ุงูุทุงูุจ (PDF)", type="pdf")


# =========================
# ุฃุฏูุงุช PDF + ูุต + JSON
# =========================
def _normalize_dash(s: str) -> str:
    return re.sub(r"[โโโ]", "-", (s or "").strip())

def _parse_page_range(rng: str):
    if not rng or not rng.strip():
        return None
    s = _normalize_dash(rng)
    m = re.match(r"^\s*(\d+)\s*-\s*(\d+)\s*$", s)
    if not m:
        return None
    a, b = int(m.group(1)), int(m.group(2))
    if a <= 0 or b <= 0:
        return None
    if a > b:
        a, b = b, a
    return (a, b)

@st.cache_data(show_spinner=False)
def extract_text_from_pdf_textonly(pdf_bytes: bytes, page_range_1idx=None) -> str:
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    start0, end0 = 0, doc.page_count - 1
    if page_range_1idx:
        a, b = page_range_1idx
        start0 = max(0, a - 1)
        end0 = min(doc.page_count - 1, b - 1)

    parts = []
    for i in range(start0, end0 + 1):
        page = doc.load_page(i)
        parts.append(page.get_text("text"))
    doc.close()
    return "\n".join(parts).strip()

def safe_clip(text: str, max_chars: int) -> str:
    return (text or "")[:max_chars]

def strip_control_chars(s: str) -> str:
    if not s:
        return ""
    return re.sub(r"[\x00-\x08\x0B\x0C\x0E-\x1F]", "", s)

def repair_json_text(s: str) -> str:
    s = strip_control_chars(s).strip()
    s = re.sub(r"^```(?:json)?\s*", "", s)
    s = re.sub(r"\s*```$", "", s)

    start = s.find("{")
    end = s.rfind("}")
    if start != -1 and end != -1 and end > start:
        s = s[start:end + 1]

    s = s.replace("โ", '"').replace("โ", '"').replace("โ", '"').replace("โ", "'").replace("โ", "'")
    s = s.replace("ุ", ",")
    s = re.sub(r",\s*([}\]])", r"\1", s)

    s = re.sub(r'(")\s*\n\s*(")', r'\1,\n\2', s)
    s = re.sub(r'(\d)\s*\n\s*(")', r'\1,\n\2', s)
    s = re.sub(r'(})\s*\n\s*(")', r'\1,\n\2', s)
    s = re.sub(r'(])\s*\n\s*(")', r'\1,\n\2', s)
    return s

def parse_json_robust(raw: str) -> dict:
    if not raw:
        raise ValueError("ุฑุฏ ูุงุฑุบ ูู ุงููููุฐุฌ")
    raw = strip_control_chars(raw)
    try:
        return json.loads(raw)
    except Exception:
        fixed = repair_json_text(raw)
        return json.loads(fixed)


# =========================
# ุงุฎุชูุงุฑ ููุฏูู (ูุชูุงุฏู 404)
# =========================
def pick_model(preferred="gemini-2.5-flash"):
    models = [
        m for m in genai.list_models()
        if "generateContent" in getattr(m, "supported_generation_methods", [])
    ]
    names = [m.name for m in models]  # models/...

    pref = preferred if preferred.startswith("models/") else f"models/{preferred}"
    if pref in names:
        return genai.GenerativeModel(pref), pref

    for n in names:
        if "flash" in n and "preview" not in n:
            return genai.GenerativeModel(n), n

    return genai.GenerativeModel(names[0]), names[0]


# =========================
# OCR ุนุจุฑ Gemini (ุนูุฏ ูุดู ุงุณุชุฎุฑุงุฌ ุงููุต ูู PDF)
# =========================
def _page_indices(doc, page_range_1idx):
    start0, end0 = 0, doc.page_count - 1
    if page_range_1idx:
        a, b = page_range_1idx
        start0 = max(0, a - 1)
        end0 = min(doc.page_count - 1, b - 1)
    return list(range(start0, end0 + 1))

def ocr_pdf_with_gemini(model, pdf_bytes: bytes, page_range_1idx=None, max_pages: int = 12) -> str:
    if Image is None:
        raise RuntimeError("Pillow ุบูุฑ ูุชููุฑ. ุฃุถู pillow ุฅูู requirements.txt")
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    pages = _page_indices(doc, page_range_1idx)
    if len(pages) > max_pages:
        pages = pages[:max_pages]

    out_parts = []
    ocr_prompt = (
        "ุงุณุชุฎุฑุฌ ุงููุต ุงูุธุงูุฑ ูู ุงูุตูุฑุฉ ุจุฏูุฉ ุนุงููุฉ (ุนุฑุจู/ุฅูุฌููุฒู/ุฃุฑูุงู/ุฑููุฒ). "
        "ุงูุชุจ ุงููุต ููุท ููุง ูู ุฏูู ุฅุนุงุฏุฉ ุตูุงุบุฉ. "
        "ุญุงูุธ ุนูู ุชุฑุชูุจ ุงูุณุทูุฑ. "
        "ูุง ุชุถู ุฃู ูููุงุช ุบูุฑ ููุฌูุฏุฉ."
    )

    for pno in pages:
        page = doc.load_page(pno)
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2), alpha=False)
        png_bytes = pix.tobytes("png")
        img = Image.open(BytesIO(png_bytes))

        resp = model.generate_content(
            [ocr_prompt, img],
            generation_config={"temperature": 0.0, "top_p": 1.0, "max_output_tokens": 2048},
        )
        txt = (getattr(resp, "text", "") or "").strip()
        if txt:
            out_parts.append(txt)

    doc.close()
    return "\n\n".join(out_parts).strip()

def extract_text_auto(model, pdf_bytes: bytes, page_range_1idx=None, max_pages_ocr: int = 12) -> Tuple[str, str]:
    """
    ูุฑุฌุน (text, mode) ุญูุซ mode ุฅูุง 'text' ุฃู 'ocr'
    """
    txt = extract_text_from_pdf_textonly(pdf_bytes, page_range_1idx)
    compact = re.sub(r"\s+", "", txt or "")
    if len(compact) >= 200:
        return txt, "text"

    # OCR ุนูุฏ ูุดู ุงููุต
    txt_ocr = ocr_pdf_with_gemini(model, pdf_bytes, page_range_1idx, max_pages=max_pages_ocr)
    if txt_ocr.strip():
        return txt_ocr, "ocr"

    return txt, "text"


# =========================
# ุงุณุชุฑุฌุงุน ุณูุงู ูู ูุซููุฉ ุงูุชูููู/ุงููุชุงุจ (ุชูููู ุงููููุณุฉ)
# =========================
_ARABIC_DIACRITICS = re.compile(r"[\u064B-\u065F\u0670\u06D6-\u06ED]")

def norm_ar(s: str) -> str:
    s = s or ""
    s = _ARABIC_DIACRITICS.sub("", s)
    s = s.replace("ุฃ", "ุง").replace("ุฅ", "ุง").replace("ุข", "ุง")
    s = s.replace("ู", "ู").replace("ุฉ", "ู")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def chunk_text(text: str, chunk_size: int = 1400, overlap: int = 250) -> List[str]:
    text = text or ""
    if len(text) <= chunk_size:
        return [text]
    chunks = []
    i = 0
    while i < len(text):
        j = min(len(text), i + chunk_size)
        chunks.append(text[i:j])
        i = max(j - overlap, i + 1)
    return chunks

def score_overlap(query: str, chunk: str) -> float:
    q = set(norm_ar(query).split())
    c = set(norm_ar(chunk).split())
    if not q or not c:
        return 0.0
    inter = len(q & c)
    return inter / (len(q) + 1e-9)

def top_k_chunks(query: str, text: str, k: int = 4) -> List[str]:
    chunks = chunk_text(text, chunk_size=1400, overlap=250)
    scored = sorted(((score_overlap(query, ch), ch) for ch in chunks), key=lambda x: x[0], reverse=True)
    best = [ch for sc, ch in scored[:k] if sc > 0]
    return best if best else (chunks[:k] if chunks else [])


# =========================
# ูุฑุดูุญ ุฃููู A01/A02 (ูุณุงุนุฏ ููุท)
# =========================
A02_TRIGGERS = [
    "ุงุณุชูุชุฌ", "ุญูู", "ูุงุฑู", "ุนูู", "ูุณุฑ", "ุจุฑุฑ", "ูุงูุด", "ุงุซุจุช", "ุจุฑูู",
    "ูู ุงูุฑุณู", "ูู ุงูุฌุฏูู", "ุงุฑุณู", "ูุซู ุจูุงููุง", "ููุญูู", "ุฑุณู ุจูุงูู", "ูุฎุทุท", "ุจูุงูุงุช",
    "ุชุฌุฑุจุฉ", "ุชุญููู", "ุงุณุชูุตุงุก", "ุตูู", "ุงูุชุฑุญ", "ุชููุน", "ุงุณุชุฎูุต", "ูุณุฑ ุงููุชุงุฆุฌ",
    "ูุชุนุฏุฏุฉ", "ุฎุทูุงุช", "ุชูููู", "ุณูุงู ุบูุฑ ูุฃููู"
]
A01_TRIGGERS = [
    "ุนุฑู", "ุงุฐูุฑ", "ุนุฏุฏ", "ุณู", "ูุง ุงูููุตูุฏ", "ูุง ูู", "ุญุฏุฏ", "ุตู", "ูุถุญ", "ุงูุชุจ", "ุจูู ูุนูู",
    "ูุงููู", "ูุญุฏุฉ", "ุฑูุฒ", "ูุตุทูุญ", "ุชุนุฑูู"
]

def heuristic_assessment_objective(item_text: str) -> str:
    t = norm_ar(item_text)

    for w in A02_TRIGGERS:
        if norm_ar(w) in t:
            return "A02"

    for w in A01_TRIGGERS:
        if norm_ar(w) in t:
            return "A01"

    # ุจูุงูุงุช/ุฑุณูู ุบุงูุจูุง A02
    if re.search(r"(ูู ุงูุฑุณู|ูู ุงูุฌุฏูู|ุจูุงูุงุช|ููุญูู|ูุฎุทุท)", item_text):
        return "A02"

    # ุงูุชุฑุงุถู ูุญุงูุธ
    return "A01"


# =========================
# LLM: ุชูููุฏ JSON + ุชุตุญูุญ ุชููุงุฆู
# =========================
def generate_json(model, prompt: str, tries: int = 3) -> Tuple[dict, str]:
    last_raw = ""
    last_err = ""

    base_cfg = {
        "temperature": 0.0,
        "top_p": 1.0,
        "max_output_tokens": 8192,
    }

    for attempt in range(1, tries + 1):
        cfg = dict(base_cfg)
        if attempt == 1:
            cfg["response_mime_type"] = "application/json"

        try:
            resp = model.generate_content(prompt, generation_config=cfg)
        except TypeError:
            cfg.pop("response_mime_type", None)
            resp = model.generate_content(prompt, generation_config=cfg)

        last_raw = getattr(resp, "text", "") or ""

        try:
            return parse_json_robust(last_raw), last_raw
        except Exception as e:
            last_err = str(e)
            snippet = safe_clip(last_raw, 25000)
            prompt = f"""
ุฃุตูุญ JSON ุงูุชุงูู ููุตุจุญ JSON ุตุงูุญ 100% ููุง ุชูุชุจ ุฃู ุดูุก ุบูุฑ JSON.
ููุงุนุฏ ุตุงุฑูุฉ:
- ุงุณุชุฎุฏู " ููููุงุชูุญ ููุท
- ูุง ุชุณุชุฎุฏู " ุฏุงุฎู ุงูููู (ุงุณุชุจุฏููุง ุจู ')
- ูุง ุชุถุน ุฃุณุทุฑ ุฌุฏูุฏุฉ ุฏุงุฎู ุงูููู
- ุงุณุชุฎุฏู ุงููุงุตูุฉ ุงูุฅูุฌููุฒูุฉ , ููุท

JSON ุบูุฑ ุตุงูุญ:
{snippet}
"""

    raise ValueError(f"ูุดู ุชูููุฏ JSON ุตุงูุญ. ุขุฎุฑ ุฎุทุฃ: {last_err}")


# =========================
# ุงุณุชุฎุฑุงุฌ ููุฑุฏุงุช ุงูุงุฎุชุจุงุฑ (ุฎุทูุฉ 1)
# =========================
def extract_items_via_llm(model, txt_test: str) -> List[Dict]:
    prompt = f"""
ุฃูุช ูุณุงุนุฏ ุชุฏููู ุงุฎุชุจุงุฑุงุช.
ูููุชู: ุงุณุชุฎุฑุงุฌ "ุงูููุฑุฏุงุช/ุงูุฃุณุฆูุฉ" ูู ูุต ุงูุงุฎุชุจุงุฑ ูุฅุฑุฌุงุน JSON ููุท.

ููุงุนุฏ:
- JSON ููุท.
- ููู ููุฑุฏุฉ: ุฑูู ุงูููุฑุฏุฉ (number) + ูุต ุงูููุฑุฏุฉ (text) + ุงูุฏุฑุฌุฉ ุฅู ููุฌุฏุช (marks ููุต).
- ุฅุฐุง ูู ูุธูุฑ ุฑูู ุงูููุฑุฏุฉ ุจูุถูุญ: ุฃูุดุฆ ุชุฑููููุง ูุชุณูุณููุง 1..n.
- ูุง ุชุถุน " ุฏุงุฎู ุงูููู.

ุตูุบุฉ ุงูุฅุฎุฑุงุฌ:
{{
  "items":[
    {{"number":"1","text":"...","marks":"1"}}
  ]
}}

ูุต ุงูุงุฎุชุจุงุฑ:
{safe_clip(txt_test, 75000)}
"""
    data, _ = generate_json(model, prompt, tries=3)
    items = data.get("items", []) or []

    cleaned = []
    seq = 1
    for it in items:
        num = str(it.get("number", "")).strip() or str(seq)
        txt = str(it.get("text", "")).strip()
        marks = str(it.get("marks", "")).strip()
        if txt:
            cleaned.append({"number": num, "text": txt, "marks": marks})
            seq += 1
    return cleaned


# =========================
# ุชุญููู ููุฑุฏุฉ ูุงุญุฏุฉ (ุฎุทูุฉ 2) ูุน ุงูุชุฒุงู ุฑุณูู A01/A02
# =========================
def analyze_one_item(model, item: Dict, policy_text: str, book_text: str) -> Dict:
    item_no = str(item.get("number", "")).strip()
    item_text = str(item.get("text", "")).strip()
    item_marks = str(item.get("marks", "")).strip() or "-"

    policy_snips = top_k_chunks(item_text, policy_text, k=4)
    book_snips = top_k_chunks(item_text, book_text, k=3)

    ao_hint = heuristic_assessment_objective(item_text)

    prompt = f"""
ุฃูุช ุฎุจูุฑ ุชูููู ููู ูุซููุฉ ุงูุชูููู.
ุญููู ููุฑุฏุฉ ูุงุญุฏุฉ ููุท ูุฃุฎุฑุฌ JSON ููุท.

ุงูุชุนุฑูู ุงูุฑุณูู (ุงูุชุฒู ุจู ุญุฑูููุง ุนูุฏ ุงุฎุชูุงุฑ ูุฏู ุงูุชูููู):
{A01_DEFINITION}

{A02_DEFINITION}

ูุงุนุฏุฉ ูุฑุงุฑ ูุงุถุญุฉ:
- ุฅุฐุง ูุงู ุงููุทููุจ: ุชุทุจูู/ุชุญููู/ุงุณุชูุชุงุฌ/ุชูุณูุฑ ุณุจุจู/ููุงุฑูุฉ ุชุญููููุฉ/ุชุญููู ุจูุงูุงุช ุฃู ุฑุณูู/ูุชุงุฆุฌ/ุชุฌุฑุจุฉ/ุงุณุชูุตุงุก/ุญู ูุดููุฉ/ุนูููุงุช ูุชุนุฏุฏุฉ ุงูุฎุทูุงุช โ A02
- ุฅุฐุง ูุงู ุงููุทููุจ: ุชุฐูุฑ/ุชุนุฑูู/ุฐูุฑ/ุชุนุฏุงุฏ/ุชุญุฏูุฏ/ุชุณููุฉ/ูุตู/ุชูุถูุญ ุจุณูุท/ูุงููู ุฃู ูุญุฏุฉ ุฃู ุฑูุฒ/ุชุนููุถ ุจุณูุท/ุนูููุฉ ุฎุทูุฉ ูุงุญุฏุฉ โ A01
- ุฅุฐุง ูุงู ุงูุณุคุงู ูุฌูุน ุจูู ุชุฐูุฑ + ุชุทุจูู ุฃู ูุทูุจ ุฌุฒุกูุง ุจุณูุทูุง ุซู ุชุทุจูููุง โ A01/A02

ููุงุญุธุฉ: ูุฑุดุญ ุฃููู (ููุณ ููุงุฆููุง): {ao_hint}

ููุงุนุฏ ุฅุฎุฑุงุฌ ุตุงุฑูุฉ:
- JSON ููุท ุฏูู ุฃู ูุต ุฅุถุงูู.
- ูุง ุชุถุน " ุฏุงุฎู ุงูููู (ุงุณุชุจุฏููุง ุจู ' ุฅู ุงุญุชุฌุช).
- ุงุฌุนู ุงูููู ูุตูุฑุฉ ููุงุถุญุฉ.
- learning_objective: ุงุฎุชุฑ ุนุจุงุฑุฉ/ุจูุฏ ูู ูุซููุฉ ุงูุชูููู "ููุง ูู" ูุฏุฑ ุงูุฅููุงู ูู ุงูููุงุทุน ุงููุฑููุฉุ ููุง ุชุฎุชุฑ ูู ุฎุงุฑุฌูุง ุฅูุง ุนูุฏ ุงูุถุฑูุฑุฉ (ูุนูุฏูุง ุถุน '-').

ุตูุบุฉ JSON ุงููุทููุจุฉ:
{{
  "mufrada": "{item_no}",
  "learning_objective": "...",
  "assessment_objective": "A01 ุฃู A02 ุฃู A01/A02",
  "marks": "{item_marks}",
  "note_type": "ุตูุงุบุฉ ุฃู ุนูููุฉ ุฃู ูููุฉ ุชุดูู ุงูุฑุณู ุฃู ูุง ุชูุฌุฏ",
  "note": "...",
  "edit": "...",
  "ao_reason": "ุณุจุจ ุฏููู ููุฎุชุตุฑ ููุงุฎุชูุงุฑ (ููุน ููุงุฑุฉ/ูุทููุจ)"
}}

ุงูููุฑุฏุฉ ุฑูู {item_no}:
{item_text}

ููุงุทุน ูู ูุซููุฉ ุงูุชูููู (ุงูุฃูุซุฑ ุตูุฉ):
{chr(10).join([f"- {s}" for s in policy_snips])}

ููุงุทุน ูู ูุชุงุจ ุงูุทุงูุจ (ุงูุฃูุซุฑ ุตูุฉ):
{chr(10).join([f"- {s}" for s in book_snips])}
"""
    out, raw = generate_json(model, prompt, tries=3)

    out["mufrada"] = item_no  # ุฑูู ุงูููุฑุฏุฉ ููุท

    allowed = {"A01", "A02", "A01/A02"}
    ao = str(out.get("assessment_objective", "")).strip()
    if ao not in allowed:
        out["assessment_objective"] = ao_hint

    strong_a02 = bool(re.search(r"(ูู ุงูุฑุณู|ูู ุงูุฌุฏูู|ุจูุงูุงุช|ููุญูู|ูุฎุทุท|ุงุณุชูุชุฌ|ุญูู|ุนูู|ูุณุฑ ุงููุชุงุฆุฌ|ุงุฑุณู|ูุซู ุจูุงููุง)", item_text))
    if strong_a02 and str(out.get("assessment_objective", "")).strip() == "A01":
        fix_prompt = f"""
ุฑุงุฌุน ุชุตููู ูุฏู ุงูุชูููู ููุท ููู ุงูุชุนุฑูู ุงูุฑุณูู.
ุฃุฎุฑุฌ JSON ููุท: {{"assessment_objective":"A01/A02","ao_reason":"..."}}

ุงูุชุนุฑูู ุงูุฑุณูู:
{A01_DEFINITION}
{A02_DEFINITION}

ุงูููุฑุฏุฉ:
{item_text}

ุงูุชุตููู ุงูุญุงูู: A01
ุฃุนุฏ ุงูุชูููู ุจุฏูุฉ ุดุฏูุฏุฉ.
"""
        try:
            fix, _ = generate_json(model, fix_prompt, tries=2)
            new_ao = str(fix.get("assessment_objective", "")).strip()
            if new_ao in allowed:
                out["assessment_objective"] = new_ao
            if fix.get("ao_reason"):
                out["ao_reason"] = fix["ao_reason"]
        except Exception:
            pass

    out["_item_text"] = item_text
    out["_raw"] = raw
    return out


# =========================
# ุงูุฌุฏูู ุงูุนุงูู + ูุณุจุฉ ุงููุทุงุจูุฉ
# =========================
def compute_percent_match(items: List[Dict]) -> int:
    if not items:
        return 0
    ok = 0
    for it in items:
        lo = str(it.get("learning_objective", "")).strip()
        if lo and lo not in {"-", "ุบูุฑ ูุญุฏุฏ", "ุบูุฑ ูุชููุฑ"}:
            ok += 1
    return int(round(100 * ok / len(items)))

def detect_mcq(item_text: str) -> bool:
    t = item_text or ""
    return bool(re.search(r"(ุฃ\)|ุจ\)|ุฌ\)|ุฏ\))|(\bA\b|\bB\b|\bC\b|\bD\b)", t))

def detect_long_answer(item_text: str) -> bool:
    t = norm_ar(item_text)
    return any(norm_ar(x) in t for x in ["ูุงูุด", "ุจุฑูู", "ุงุซุจุช", "ุงูุชุจ ุชูุฑูุฑ", "ุนูู ุชุนูููุง", "ูุณุฑ ุชูุณูุฑุง"])

def build_working_table(items: List[Dict]) -> Dict:
    n_items = len(items)
    mcq_count = sum(1 for it in items if detect_mcq(it.get("_item_text", "")))
    long_count = sum(1 for it in items if detect_long_answer(it.get("_item_text", "")))

    a01 = sum(1 for it in items if str(it.get("assessment_objective", "")).strip() == "A01")
    a02 = sum(1 for it in items if str(it.get("assessment_objective", "")).strip() == "A02")
    mix = sum(1 for it in items if str(it.get("assessment_objective", "")).strip() == "A01/A02")

    wt = {
        "ุนุฏุฏ ุงูููุฑุฏุงุช": {"value": str(n_items), "status": "ูุทุงุจู"},
        "ุนุฏุฏ ุงูุฏุฑูุณ": {"value": "-", "status": "ูุทุงุจู"},
        "ุฏุฑุฌุงุช ุฃูุฏุงู ุงูุชูููู (A01,A02)": {"value": f"A01={a01} | A02={a02} | A01/A02={mix}", "status": "ูุทุงุจู"},
        "ูู ุชูุฌุฏ ููุฑุฏุฉ ุทูููุฉ ุงูุฅุฌุงุจุฉุ": {"value": "ูุนู" if long_count > 0 else "ูุง", "status": "ูุทุงุจู"},
        "ูู ุชูุฌุฏ ููุฑุฏุชุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏุ": {"value": "ูุนู" if mcq_count >= 2 else "ูุง", "status": "ูุทุงุจู"},
        "ูู ููุฑุฏุงุช ุงูุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ ุชุญุชูู ุนูู (ุฅุฌุงุจุงุช ุฎุงุทุฆุฉ) ูุดุชุชุงุช ููุทููุฉุ": {"value": "-", "status": "ูุทุงุจู"},
        "ูู ุตูุงุบุฉ ุงูููุฑุฏุงุช ูุญุฌู ูููุน ุงูุฎุท ูุงุถุญ ูููุฑุงุกุฉุ": {"value": "-", "status": "ูุทุงุจู"},
        "ูู ุงูุฃุดูุงู ูุงูุฑุณููุงุช ูุงุถุญุฉุ": {"value": "-", "status": "ูุทุงุจู"},
    }
    return wt


# =========================
# Word
# =========================
def _rtl_paragraph(paragraph):
    paragraph.alignment = WD_ALIGN_PARAGRAPH.RIGHT

def _rtl_cell(cell):
    for p in cell.paragraphs:
        _rtl_paragraph(p)

def exam_label_ar(exam_type_value: str) -> str:
    return "ุงููุตูุฑุฉ" if exam_type_value == "ูุตูุฑ" else "ุงูุงุณุชูุตุงุฆูุฉ"

def build_report_docx(data: dict, exam_label: str) -> bytes:
    doc = Document()

    title = f"ูููุฐุฌ ุชูุฑูุฑ ุชุทุจูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุชุญููู ุงูุงุฎุชุจุงุฑุงุช {exam_label}"
    p = doc.add_paragraph(title)
    _rtl_paragraph(p)
    doc.add_paragraph("")

    p = doc.add_paragraph("ุฌุฏูู ุชุญููู ุงูููุฑุฏุงุช ุงูุงูุชุญุงููุฉ")
    _rtl_paragraph(p)

    headers = [
        "ุงูููุฑุฏุฉ",
        "ุงููุฏู ุงูุชุนูููู",
        "ูุฏู ุงูุชูููู (A01,A02)",
        "ุงูุฏุฑุฌุฉ",
        "ููุน ุงูููุงุญุธุฉ (ุตูุงุบุฉุ ุนูููุฉุ ูููุฉ ุชุดูู ุงูุฑุณู)",
        "ุงูููุงุญุธุฉ",
        "ุงูุชุนุฏูู",
    ]

    items = data.get("items", []) or []
    rows_needed = max(1, len(items)) + 1

    t1 = doc.add_table(rows=rows_needed, cols=len(headers))
    t1.style = "Table Grid"
    t1.alignment = WD_TABLE_ALIGNMENT.RIGHT

    for j, h in enumerate(headers):
        t1.cell(0, j).text = h
        _rtl_cell(t1.cell(0, j))

    for i, item in enumerate(items, start=1):
        t1.cell(i, 0).text = str(item.get("mufrada", "-")).strip()
        t1.cell(i, 1).text = str(item.get("learning_objective", "-")).strip()
        t1.cell(i, 2).text = str(item.get("assessment_objective", "-")).strip()
        t1.cell(i, 3).text = str(item.get("marks", "-")).strip()
        t1.cell(i, 4).text = str(item.get("note_type", "-")).strip()
        t1.cell(i, 5).text = str(item.get("note", "-")).strip()
        t1.cell(i, 6).text = str(item.get("edit", "-")).strip()
        for j in range(len(headers)):
            _rtl_cell(t1.cell(i, j))

    doc.add_paragraph("")

    p = doc.add_paragraph(f"ุงูุฌุฏูู ุงูุนุงูู ููุงุฎุชุจุงุฑ {exam_label}")
    _rtl_paragraph(p)

    wt = data.get("working_table", {}) or {}
    rows_order = [
        "ุนุฏุฏ ุงูููุฑุฏุงุช",
        "ุนุฏุฏ ุงูุฏุฑูุณ",
        "ุฏุฑุฌุงุช ุฃูุฏุงู ุงูุชูููู (A01,A02)",
        "ูู ุชูุฌุฏ ููุฑุฏุฉ ุทูููุฉ ุงูุฅุฌุงุจุฉุ",
        "ูู ุชูุฌุฏ ููุฑุฏุชุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏุ",
        "ูู ููุฑุฏุงุช ุงูุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ ุชุญุชูู ุนูู (ุฅุฌุงุจุงุช ุฎุงุทุฆุฉ) ูุดุชุชุงุช ููุทููุฉุ",
        "ูู ุตูุงุบุฉ ุงูููุฑุฏุงุช ูุญุฌู ูููุน ุงูุฎุท ูุงุถุญ ูููุฑุงุกุฉุ",
        "ูู ุงูุฃุดูุงู ูุงูุฑุณููุงุช ูุงุถุญุฉุ",
    ]

    t2 = doc.add_table(rows=1 + len(rows_order), cols=3)
    t2.style = "Table Grid"
    t2.alignment = WD_TABLE_ALIGNMENT.RIGHT

    t2.cell(0, 0).text = "ุงูุจูุฏ"
    t2.cell(0, 1).text = "ุงูุนุฏุฏ / ุงูุฏุฑุฌุงุช โ ูุนู / ูุง"
    t2.cell(0, 2).text = "ูุทุงุจู / ุบูุฑ ูุทุงุจู"
    for j in range(3):
        _rtl_cell(t2.cell(0, j))

    for i, row_label in enumerate(rows_order, start=1):
        t2.cell(i, 0).text = row_label
        entry = wt.get(row_label, {}) or {}
        t2.cell(i, 1).text = str(entry.get("value", "-")).strip()
        t2.cell(i, 2).text = str(entry.get("status", "-")).strip()
        for j in range(3):
            _rtl_cell(t2.cell(i, j))

    p = doc.add_paragraph(f"ุงูุชูุฏูุฑ ุงูุนุงู ููุงุฎุชุจุงุฑ {exam_label}")
    _rtl_paragraph(p)

    overall = data.get("overall", {}) or {}
    summary = str(overall.get("summary", "-")).strip()
    percent = overall.get("percent_match", "")

    text = summary
    if percent != "" and percent is not None:
        text = f"{summary}\nูุณุจุฉ ุงููุทุงุจูุฉ ูููุนุงููุฑ: {percent}%"
    p = doc.add_paragraph(text.strip())
    _rtl_paragraph(p)

    bio = BytesIO()
    doc.save(bio)
    return bio.getvalue()


# =========================
# ุนุฑุถ HTML ููุฌุฏุงูู ุฏุงุฎู ุงูุตูุญุฉ (ููู ุงููููุฐุฌ)
# =========================
def render_table_html(headers: List[str], rows: List[List[str]]) -> str:
    th = "".join([f"<th>{h}</th>" for h in headers])
    trs = []
    for r in rows:
        tds = "".join([f"<td>{(c if c is not None and str(c).strip() else '-')}</td>" for c in r])
        trs.append(f"<tr>{tds}</tr>")
    return f'<table class="tbl"><thead><tr>{th}</tr></thead><tbody>{"".join(trs)}</tbody></table>'


# =========================
# ุงูุชูููุฐ
# =========================
run = st.button("๐ ุจุฏุก ุงูุชุญููู ุงูุดุงูู")

if run:
    if not api_key:
        st.error("ุงูุฑุฌุงุก ุฅุฏุฎุงู ููุชุงุญ API ุฃูููุง.")
        st.stop()

    if not file_test or not file_policy or not file_book:
        st.error("ุงูุฑุฌุงุก ุฑูุน ุงููููุงุช ุงูุซูุงุซุฉ: ุงูุงุฎุชุจุงุฑ + ูุซููุฉ ุงูุชูููู + ูุชุงุจ ุงูุทุงูุจ.")
        st.stop()

    try:
        genai.configure(api_key=api_key)
        model, model_name = pick_model()
        st.sidebar.success(f"โ ุงููููุฐุฌ ุงููุฎุชุงุฑ: {model_name}")

        pr = _parse_page_range(pages_range)
        exam_label = exam_label_ar(exam_type)

        with st.spinner("ุฌุงุฑู ูุฑุงุกุฉ ุงููููุงุช (ูุน OCR ุชููุงุฆููุง ุนูุฏ ุงูุญุงุฌุฉ)..."):
            txt_test, mode_test = extract_text_auto(model, file_test.getvalue(), pr, max_pages_ocr=12)
            txt_policy, mode_policy = extract_text_auto(model, file_policy.getvalue(), pr, max_pages_ocr=12)
            txt_book, mode_book = extract_text_auto(model, file_book.getvalue(), pr, max_pages_ocr=12)

            txt_test = safe_clip(txt_test, 80000)
            txt_policy = safe_clip(txt_policy, 130000)
            txt_book = safe_clip(txt_book, 100000)

        with st.spinner("ุฌุงุฑู ุงุณุชุฎุฑุงุฌ ููุฑุฏุงุช ุงูุงุฎุชุจุงุฑ..."):
            items_base = extract_items_via_llm(model, txt_test)

        if not items_base:
            st.error("ูู ุฃุณุชุทุน ุงุณุชุฎุฑุงุฌ ููุฑุฏุงุช ูู ููู ุงูุงุฎุชุจุงุฑ. ุฌุฑูุจ ุชุถููู ูุทุงู ุงูุตูุญุงุช.")
            st.stop()

        analyzed_items = []
        prog = st.progress(0)
        total = len(items_base)

        for idx, it in enumerate(items_base, start=1):
            with st.spinner(f"ุชุญููู ุงูููุฑุฏุฉ {it.get('number')} ..."):
                analyzed_items.append(analyze_one_item(model, it, txt_policy, txt_book))
            prog.progress(int(100 * idx / total))

        percent_match = compute_percent_match(analyzed_items)
        working_table = build_working_table(analyzed_items)

        compact = [
            {"mufrada": x.get("mufrada"), "assessment_objective": x.get("assessment_objective"),
             "note_type": x.get("note_type"), "note": x.get("note")}
            for x in analyzed_items
        ]

        overall_prompt = f"""
ุฃูุช ุฎุจูุฑ ุชูููู. ุงูุชุจ ุชูุฏูุฑูุง ุนุงููุง ูุฎุชุตุฑูุง (3-5 ุฃุณุทุฑ) ุนู ุงูุงุฎุชุจุงุฑ {exam_label}.
ุฑูุฒ ุนูู: ุชูุงุฒู A01/A02 ููู ุงูุชุนุฑูู ุงูุฑุณููุ ุฌูุฏุฉ ุงูุตูุงุบุฉ ูุงูุฏูุฉ ุงูุนูููุฉุ ูููุงุทู ุงูุชุญุณูู.
ูุง ุชุณุชุฎุฏู " ุฏุงุฎู ุงููุต.

ุฃุฎุฑุฌ JSON ููุท:
{{"summary":"..."}}

ุงูุจูุงูุงุช ุงููุฎุชุตุฑุฉ:
{json.dumps(compact, ensure_ascii=False)}
"""
        overall_data, _ = generate_json(model, overall_prompt, tries=2)
        overall_summary = str(overall_data.get("summary", "")).strip() or "-"

        report_data = {
            "items": analyzed_items,
            "working_table": working_table,
            "overall": {"summary": overall_summary, "percent_match": percent_match},
        }

        st.markdown("---")
        st.subheader("ุฌุฏูู ุชุญููู ุงูููุฑุฏุงุช ุงูุงูุชุญุงููุฉ")

        headers1 = [
            "ุงูููุฑุฏุฉ",
            "ุงููุฏู ุงูุชุนูููู",
            "ูุฏู ุงูุชูููู (A01,A02)",
            "ุงูุฏุฑุฌุฉ",
            "ููุน ุงูููุงุญุธุฉ (ุตูุงุบุฉุ ุนูููุฉุ ูููุฉ ุชุดูู ุงูุฑุณู)",
            "ุงูููุงุญุธุฉ",
            "ุงูุชุนุฏูู",
        ]

        rows1 = []
        for it in analyzed_items:
            rows1.append([
                str(it.get("mufrada", "-")).strip(),
                str(it.get("learning_objective", "-")).strip(),
                str(it.get("assessment_objective", "-")).strip(),
                str(it.get("marks", "-")).strip(),
                str(it.get("note_type", "-")).strip(),
                str(it.get("note", "-")).strip(),
                str(it.get("edit", "-")).strip(),
            ])

        st.markdown(render_table_html(headers1, rows1), unsafe_allow_html=True)

        st.markdown("")
        st.subheader(f"ุงูุฌุฏูู ุงูุนุงูู ููุงุฎุชุจุงุฑ {exam_label}")

        headers2 = ["ุงูุจูุฏ", "ุงูุนุฏุฏ / ุงูุฏุฑุฌุงุช โ ูุนู / ูุง", "ูุทุงุจู / ุบูุฑ ูุทุงุจู"]
        rows2 = []
        rows_order = [
            "ุนุฏุฏ ุงูููุฑุฏุงุช",
            "ุนุฏุฏ ุงูุฏุฑูุณ",
            "ุฏุฑุฌุงุช ุฃูุฏุงู ุงูุชูููู (A01,A02)",
            "ูู ุชูุฌุฏ ููุฑุฏุฉ ุทูููุฉ ุงูุฅุฌุงุจุฉุ",
            "ูู ุชูุฌุฏ ููุฑุฏุชุงู ุงุฎุชูุงุฑ ูู ูุชุนุฏุฏุ",
            "ูู ููุฑุฏุงุช ุงูุงุฎุชูุงุฑ ูู ูุชุนุฏุฏ ุชุญุชูู ุนูู (ุฅุฌุงุจุงุช ุฎุงุทุฆุฉ) ูุดุชุชุงุช ููุทููุฉุ",
            "ูู ุตูุงุบุฉ ุงูููุฑุฏุงุช ูุญุฌู ูููุน ุงูุฎุท ูุงุถุญ ูููุฑุงุกุฉุ",
            "ูู ุงูุฃุดูุงู ูุงูุฑุณููุงุช ูุงุถุญุฉุ",
        ]
        for k in rows_order:
            entry = working_table.get(k, {}) or {}
            rows2.append([k, str(entry.get("value", "-")), str(entry.get("status", "-"))])

        st.markdown(render_table_html(headers2, rows2), unsafe_allow_html=True)

        st.markdown("")
        st.subheader(f"ุงูุชูุฏูุฑ ุงูุนุงู ููุงุฎุชุจุงุฑ {exam_label}")
        st.markdown(
            f'<div class="report-box">{overall_summary}<br><br>ูุณุจุฉ ุงููุทุงุจูุฉ ูููุนุงููุฑ: {percent_match}%</div>',
            unsafe_allow_html=True
        )

        with st.expander("ุนุฑุถ ูุต ูู ููุฑุฏุฉ + ุณุจุจ ุชุตููู A01/A02 (ูููุฑุงุฌุนุฉ)"):
            for it in analyzed_items:
                st.markdown(f"**ุงูููุฑุฏุฉ {it.get('mufrada')}**")
                st.write(it.get("_item_text", "-"))
                st.markdown(f"<div class='muted'>ุณุจุจ ุงูุชุตููู: {it.get('ao_reason','-')}</div>", unsafe_allow_html=True)
                st.markdown("---")

        docx_bytes = build_report_docx(report_data, exam_label)
        st.download_button(
            "๐ฅ ุชูุฒูู ุงูุชูุฑูุฑ (Word)",
            data=docx_bytes,
            file_name="Report.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

    except Exception as e:
        st.error(f"ุญุฏุซ ุฎุทุฃ: {e}")
