# app.py (Ù…ÙØ¹Ø¯Ù‘Ù„) â€” Ù†Ø³Ø®Ø© Ù…Ù‚ØªØ±Ø­Ø© ØªØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ø®ØµÙˆØµÙŠØ©
import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai
import json
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO

st.set_page_config(page_title="Ù†Ø¸Ø§Ù… ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠ", layout="wide")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    div[data-testid="stSidebar"] { text-align: right; direction: rtl; }
    div[data-testid="stMarkdownContainer"] { text-align: right; direction: rtl; }
    table { width: 100%; border-collapse: collapse; direction: rtl; margin-bottom: 20px; }
    th, td { border: 1px solid #ddd; padding: 10px; text-align: right; }
    th { background-color: #f8f9fa; }
    </style>
    """, unsafe_allow_html=True)

# ----------------------------
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# ----------------------------
def extract_pdf_text(uploaded_file):
    """ÙŠÙ‚Ø±Ø£ Ù…Ù„Ù UploadedFile Ù…Ù† Streamlit ÙˆÙŠÙØ±Ø¬Ø¹ Ù†Øµ ÙƒÙ„ ØµÙØ­Ø§ØªÙ‡"""
    if not uploaded_file:
        return ""
    data = uploaded_file.read()
    if not data:
        return ""
    try:
        doc = fitz.open(stream=data, filetype="pdf")
        texts = []
        for page in doc:
            texts.append(page.get_text())
        return "\n".join(texts)
    except Exception as e:
        # Ø¥Ù† ÙØ´Ù„ PyMuPDF Ù†Ø±Ø¬Ø¹ Ù†Øµ ÙØ§Ø±Øº Ù…Ø¹ Ø³Ø¬Ù„ Ø§Ù„Ø®Ø·Ø£ (Ø­ØªÙ‰ Ù„Ø§ ÙŠÙƒØ³Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚)
        return f"[Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF: {e}]"

def generate_word(data, subject, grade, semester, exam_type):
    doc = Document()
    header = doc.add_heading(f'ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± {subject}', 0)
    header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    para = doc.add_paragraph(f'Ø§Ù„ØµÙ: {grade} | Ø§Ù„ÙØµÙ„: {semester} | Ø§Ù„Ù†ÙˆØ¹: {exam_type}')
    para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph("-" * 50)

    # Ø¬Ø¯ÙˆÙ„ 1 - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
    doc.add_heading('1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª', level=1)
    table1 = doc.add_table(rows=1, cols=6)
    table1.style = 'Table Grid'
    hdrs = ["Ù…", "Ø§Ù„Ù‡Ø¯Ù", "Ø§Ù„Ù…Ø³ØªÙˆÙ‰", "Ø§Ù„Ø¯Ø±Ø¬Ø©", "Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©", "Ø§Ù„ØªØ¹Ø¯ÙŠÙ„"]
    for i, h in enumerate(hdrs):
        table1.rows[0].cells[i].text = h
    for item in data.get("vocab", []):
        row = table1.add_row().cells
        row[0].text = str(item.get("q", ""))
        row[1].text = item.get("obj", "")
        row[2].text = item.get("level", "")
        row[3].text = str(item.get("mark", ""))
        row[4].text = item.get("note", "")
        row[5].text = item.get("fix", "")

    # Ø¬Ø¯ÙˆÙ„ 2 - Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª
    doc.add_heading('2. Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„', level=1)
    table2 = doc.add_table(rows=1, cols=3)
    table2.style = 'Table Grid'
    hdrs2 = ["Ø§Ù„Ø¨Ù†Ø¯", "Ø§Ù„Ø¨ÙŠØ§Ù†", "Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"]
    for i, h in enumerate(hdrs2):
        table2.rows[0].cells[i].text = h
    specs = data.get("specs", {})
    mapping = {"q_count":"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "lessons":"ØªØºØ·ÙŠØ© Ø§Ù„Ø¯Ø±ÙˆØ³", "ao1":"Ø¯Ø±Ø¬Ø§Øª AO1", "ao2":"Ø¯Ø±Ø¬Ø§Øª AO2", "clarity":"Ø§Ù„ÙˆØ¶ÙˆØ­"}
    for key, label in mapping.items():
        row = table2.add_row().cells
        item = specs.get(key, {})
        row[0].text = label
        row[1].text = str(item.get("val", "-"))
        row[2].text = item.get("status", "-")

    doc.add_heading('3. Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù…', level=1)
    doc.add_paragraph(data.get("summary", ""))

    buf = BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf

# ----------------------------
# ÙˆØ§Ø¬Ù‡Ø© Ø¬Ø§Ù†Ø¨ÙŠØ©
# ----------------------------
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    api_key = st.text_input("Ù…ÙØªØ§Ø­ API (Ù„Ù† ÙŠÙØ®Ø²Ù†):", type="password")
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["ÙÙŠØ²ÙŠØ§Ø¡", "ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø£Ø­ÙŠØ§Ø¡", "Ø¹Ù„ÙˆÙ…"])
    grade = st.selectbox("Ø§Ù„ØµÙ:", ["11", "12"])
    semester = st.selectbox("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ:", ["Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ"])
    exam_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:", ["Ù‚ØµÙŠØ±", "ØªØ¬Ø±ÙŠØ¨ÙŠ/Ù†Ù‡Ø§Ø¦ÙŠ"])
    pages = st.text_input("Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª (Ù…Ø«Ù„Ø§Ù‹ 1-5):", "1-50")

# ----------------------------
# Ø§Ù„Ø¬Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ----------------------------
st.title(f"ğŸ” ØªØ¯Ù‚ÙŠÙ‚ Ø§Ø®ØªØ¨Ø§Ø± {subject} - Ø§Ù„ØµÙ {grade}")

c1, c2, c3 = st.columns(3)
with c1:
    f_test = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (PDF)", type="pdf")
with c2:
    f_policy = st.file_uploader("ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (PDF)", type="pdf")
with c3:
    f_book = st.file_uploader("ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ (PDF)", type="pdf")

if st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
    if not api_key:
        st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ API ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.")
    elif not f_test:
        st.error("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.")
    else:
        # Ø§Ø¶Ø¨Ø· Ù…ÙØªØ§Ø­ Ù…ÙƒØªØ¨Ø© Google Generative AI
        genai.configure(api_key=api_key)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙÙ‚ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±..."):
            t_test = extract_pdf_text(f_test)
            t_policy = extract_pdf_text(f_policy) if f_policy else ""
            t_book = extract_pdf_text(f_book) if f_book else ""

            # Ù„ØªØ¬Ù†Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ù†ØµÙˆØµ Ø¶Ø®Ù…Ø© Ø¬Ø¯Ø§Ù‹ØŒ Ù†Ù‚ØªØµØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„ÙƒÙ„ Ù…Ø¯Ø®Ù„ (ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·ÙˆÙ„ Ø­Ø³Ø¨ Ø­Ø§Ø¬Ø©)
            max_chunk = 4000
            t_test_snip = t_test[:max_chunk]
            t_policy_snip = t_policy[:max_chunk]
            t_book_snip = t_book[:max_chunk]

            prompt = f"""
Ø­Ù„Ù„ Ø§Ø®ØªØ¨Ø§Ø± {subject} Ù„Ù„ØµÙ {grade} ÙØµÙ„ {semester}.
Ù‚Ø§Ø±Ù† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¥Ù† ÙˆÙØ¬Ø¯Øª) ÙˆØ¨Ù…Ø­ØªÙˆÙ‰ ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨.
- ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (Ù…Ù‚ØªØ·Ù): {t_policy_snip}
- ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ (Ù…Ù‚ØªØ·Ù): ØµÙØ­Ø§Øª {pages} => {t_book_snip}
- Ù†Øµ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ù…Ù‚ØªØ·Ù): {t_test_snip}

Ø§Ø·Ø±Ø­ Ù…Ø®Ø±Ø¬Ø§Øª JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:
{{
  "vocab":[
    {{
      "q": "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„",
      "obj": "Ø§Ù„Ù‡Ø¯Ù/Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚",
      "level": "AO1|AO2|AO3|...",
      "mark": 1,
      "note": "Ù…Ù„Ø§Ø­Ø¸Ø§Øª",
      "fix": "Ø§Ù‚ØªØ±Ø§Ø­ ØªØ¹Ø¯ÙŠÙ„"
    }}
  ],
  "specs": {{
    "q_count":{{"val": 0, "status": "OK|Missing"}},
    "lessons":{{"val":"Ù‚Ø§Ø¦Ù…Ø©","status":"Covered|Not covered"}},
    "ao1":{{"val":0,"status":"OK"}},
    "ao2":{{"val":0,"status":"OK"}},
    "clarity":{{"val":"High|Low","status":"OK|Needs revision"}}
  }},
  "summary":"Ù…Ù„Ø®Øµ ØªØ­Ù„ÙŠÙ„ÙŠ Ù‚ØµÙŠØ±"
}}
"""

            # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Øª API Ø£Ø®Ø±Ù‰ Ø£Ùˆ ØµÙŠØºØ© Ù…Ø®ØªÙ„ÙØ©ØŒ Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆÙÙ‚Ø§Ù‹ Ù„Ø°Ù„Ùƒ.
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                res = model.generate_content(prompt)
                # Ù‚Ø¯ ØªØ®ØªÙ„Ù Ø§Ù„Ø®ï¿½ï¿½ØµÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø§Ù„Ù†Øµ Ø¨Ø­Ø³Ø¨ Ù†Ø³Ø®Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø©Ø› ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¥Ø°Ø§ Ù„Ù… ØªØ¹Ù…Ù„:
                raw_text = getattr(res, "text", None) or getattr(res, "content", None) or str(res)

                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒÙˆØ¯ Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Ø£Ø³ÙˆØ§Ø± ```json
                cleaned = raw_text.replace("```json", "").replace("```", "").strip()
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙˆÙ„ { ÙˆØ¢Ø®Ø± }
                start = cleaned.find("{")
                end = cleaned.rfind("}")
                if start == -1 or end == -1:
                    raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ JSON ØµØ§Ù„Ø­ ÙÙŠ Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
                js_str = cleaned[start:end+1]

                data = json.loads(js_str)

                st.success("Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

                # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª (Ø¬Ø¯ÙˆÙ„ HTML Ø¨Ø³ÙŠØ·)
                st.subheader("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª")
                vocab = data.get("vocab", [])
                if vocab:
                    rows = "".join([f"<tr><td>{i.get('q','')}</td><td>{i.get('obj','')}</td><td>{i.get('level','')}</td><td>{i.get('mark','')}</td><td>{i.get('note','')}</td><td>{i.get('fix','')}</td></tr>" for i in vocab])
                    st.markdown(f"<table><tr><th>Ù…</th><th>Ø§Ù„Ù‡Ø¯Ù</th><th>Ø§Ù„Ù…Ø³ØªÙˆÙ‰</th><th>Ø§Ù„Ø¯Ø±Ø¬Ø©</th><th>Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©</th><th>Ø§Ù„ØªØ¹Ø¯ÙŠÙ„</th></tr>{rows}</table>", unsafe_allow_html=True)
                else:
                    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ±Ø¯Ø§Øª Ù…ÙØ¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„Ù†ØªÙŠØ¬Ø©.")

                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„
                st.subheader("Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„")
                specs = data.get("specs", {})
                mapping = {"q_count":"Ø§Ù„Ø¹Ø¯Ø¯","lessons":"Ø§Ù„Ø¯Ø±ÙˆØ³","ao1":"AO1","ao2":"AO2","clarity":"Ø§Ù„ÙˆØ¶ÙˆØ­"}
                s_rows = ""
                for k, lbl in mapping.items():
                    val = specs.get(k, {}).get("val", "-")
                    status = specs.get(k, {}).get("status", "-")
                    s_rows += f"<tr><td>{lbl}</td><td>{val}</td><td>{status}</td></tr>"
                st.markdown(f"<table><tr><th>Ø§Ù„Ø¨Ù†Ø¯</th><th>Ø§Ù„Ù‚ÙŠÙ…Ø©</th><th>Ø§Ù„Ø­Ø§Ù„Ø©</th></tr>{s_rows}</table>", unsafe_allow_html=True)

                st.info(data.get("summary", ""))

                st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Word)", generate_word(data, subject, grade, semester, exam_type), "Report.docx")

            except json.JSONDecodeError as je:
                st.error("ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSON Ù…Ù† Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
                st.code(raw_text if 'raw_text' in locals() else str(je))
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {e}")
                # Ø¥Ù† ÙˆÙØ¬Ø¯ Ù…Ø®Ø±Ø¬Ø§Øª Ø®Ø§Ù… Ù†Ø¹Ø±Ø¶Ù‡Ø§ Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ
                if 'raw_text' in locals():
                    st.subheader("Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø®Ø§Ù…)")
                    st.code(raw_text)
