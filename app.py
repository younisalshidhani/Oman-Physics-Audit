# app.py â€” Ù†Ø³Ø®Ø© ÙƒØ§Ù…Ù„Ø© Ù…Ø¹Ø¯Ù‘Ù„Ø© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„
# Ù…Ù„Ø§Ø­Ø¸Ø§Øª: Ø§Ù†Ø³Ø® Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙƒØ§Ù…Ù„Ø§Ù‹ ÙˆØ§ØµÙ„Ù‡ Ù…Ø­Ù„ app.py ÙÙŠ Ù…Ø³ØªÙˆØ¯Ø¹Ùƒ Ø£Ùˆ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ.
import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai
import json
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO
import traceback

st.set_page_config(page_title="Ù†Ø¸Ø§Ù… ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠ", layout="wide")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    div[data-testid="stSidebar"] { text-align: right; direction: rtl; }
    div[data-testid="stMarkdownContainer"] { text-align: right; direction: rtl; }
    table { width: 100%; border-collapse: collapse; direction: rtl; margin-bottom: 20px; }
    th, td { border: 1px solid #ddd; padding: 10px; text-align: right; }
    th { background-color: #f8f9fa; }
    .error-box { background:#fde2e2; padding:12px; border-radius:6px; color:#900; }
    </style>
    """, unsafe_allow_html=True)

# ----------------------------
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# ----------------------------
def extract_pdf_text(uploaded_file):
    """ÙŠÙ‚Ø±Ø£ Ù…Ù„Ù UploadedFile Ù…Ù† Streamlit ÙˆÙŠÙØ±Ø¬Ø¹ Ù†Øµ ÙƒÙ„ ØµÙØ­Ø§ØªÙ‡"""
    if not uploaded_file:
        return ""
    data = uploaded_file.read()
    if not data:
        return ""
    try:
        doc = fitz.open(stream=data, filetype="pdf")
        texts = []
        for page in doc:
            texts.append(page.get_text())
        return "\n".join(texts)
    except Exception as e:
        return f"[Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF: {e}]"

def generate_word(data, subject, grade, semester, exam_type):
    doc = Document()
    header = doc.add_heading(f'ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± {subject}', 0)
    header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    para = doc.add_paragraph(f'Ø§Ù„ØµÙ: {grade} | Ø§Ù„ÙØµÙ„: {semester} | Ø§Ù„Ù†ÙˆØ¹: {exam_type}')
    para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph("-" * 50)

    # Ø¬Ø¯ÙˆÙ„ 1 - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
    doc.add_heading('1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª', level=1)
    table1 = doc.add_table(rows=1, cols=6)
    table1.style = 'Table Grid'
    hdrs = ["Ù…", "Ø§Ù„Ù‡Ø¯Ù", "Ø§Ù„Ù…Ø³ØªÙˆÙ‰", "Ø§Ù„Ø¯Ø±Ø¬Ø©", "Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©", "Ø§Ù„ØªØ¹Ø¯ÙŠÙ„"]
    for i, h in enumerate(hdrs):
        table1.rows[0].cells[i].text = h
    for item in data.get("vocab", []):
        row = table1.add_row().cells
        row[0].text = str(item.get("q", ""))
        row[1].text = item.get("obj", "")
        row[2].text = item.get("level", "")
        row[3].text = str(item.get("mark", ""))
        row[4].text = item.get("note", "")
        row[5].text = item.get("fix", "")

    # Ø¬Ø¯ÙˆÙ„ 2 - Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª
    doc.add_heading('2. Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„', level=1)
    table2 = doc.add_table(rows=1, cols=3)
    table2.style = 'Table Grid'
    hdrs2 = ["Ø§Ù„Ø¨Ù†Ø¯", "Ø§Ù„Ø¨ÙŠØ§Ù†", "Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"]
    for i, h in enumerate(hdrs2):
        table2.rows[0].cells[i].text = h
    specs = data.get("specs", {})
    mapping = {"q_count":"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "lessons":"ØªØºØ·ÙŠØ© Ø§Ù„Ø¯Ø±ÙˆØ³", "ao1":"Ø¯Ø±Ø¬Ø§Øª AO1", "ao2":"Ø¯Ø±Ø¬Ø§Øª AO2", "clarity":"Ø§Ù„ÙˆØ¶ÙˆØ­"}
    for key, label in mapping.items():
        row = table2.add_row().cells
        item = specs.get(key, {})
        row[0].text = label
        row[1].text = str(item.get("val", "-"))
        row[2].text = item.get("status", "-")

    doc.add_heading('3. Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù…', level=1)
    doc.add_paragraph(data.get("summary", ""))

    buf = BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf

def choose_model_and_list():
    """
    ÙŠØ­Ø§ÙˆÙ„ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ø«Ù… ÙŠØ®ØªØ§Ø± Ø§Ø³Ù…Ø§Ù‹ Ù…ÙÙØ¶Ù„Ø§Ù‹ Ø¥Ù† ÙˆÙØ¬Ø¯.
    ÙŠÙØ±Ø¬Ø¹ tuple: (chosen_model_name or None, raw_list_repr)
    """
    try:
        # Ø¨Ø¹Ø¶ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªØ¹Ø±Ø¶ ÙˆØ§Ø¬Ù‡Ø© Ù…Ø®ØªÙ„ÙØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ØŒ Ù†Ø¬Ø±Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø·Ø±ÙŠÙ‚Ø©
        list_result = None
        if hasattr(genai, "list_models"):
            list_result = genai.list_models()
        elif hasattr(genai, "models") and hasattr(genai.models, "list"):
            list_result = genai.models.list()
        else:
            # Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ§Ø¬Ù‡Ø© list models Ù…Ø¹Ø±ÙˆÙØ© - Ù†ÙØ¹ÙŠØ¯ None
            return None, "list_models not supported in this client version."

        # Ù†ÙØ­Ø¶Ù‘Ø± ØªÙ…Ø«ÙŠÙ„Ø§Ù‹ Ù†ØµÙŠØ§Ù‹ Ù„Ù„Ù†ØªÙŠØ¬Ø© Ù„Ø¹Ø±Ø¶Ù‡ ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ø®Ø·Ø£
        try:
            raw_list = json.dumps(list_result, default=lambda o: o.__dict__, ensure_ascii=False)
        except Exception:
            raw_list = str(list_result)

        # Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ù† ÙˆÙØ¬Ø¯Øª ÙÙŠ Ù‡ÙŠÙƒÙ„ÙŠØ© Ù…Ø¹Ø±ÙˆÙØ©
        names = []
        if isinstance(list_result, dict):
            # Ø¨Ø¹Ø¶ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø§Øª ØªØ¹ÙŠØ¯ dict Ù…Ø¹ Ù…ÙØªØ§Ø­ 'models'
            for k in ("models", "model_versions", "data"):
                if k in list_result and isinstance(list_result[k], list):
                    for entry in list_result[k]:
                        if isinstance(entry, dict) and entry.get("name"):
                            names.append(entry.get("name"))
                        elif hasattr(entry, "name"):
                            names.append(getattr(entry, "name"))
        elif isinstance(list_result, list):
            for entry in list_result:
                if isinstance(entry, dict) and entry.get("name"):
                    names.append(entry.get("name"))
                elif hasattr(entry, "name"):
                    names.append(getattr(entry, "name"))
        else:
            # fallback: stringify
            # try to parse any "name": "..." patterns
            raw = str(list_result)
            # Ø¨Ø³ÙŠØ·: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª models/... ÙÙŠ Ø§Ù„Ù†Øµ
            tokens = raw.split()
            for t in tokens:
                if "models/" in t or "gemini" in t or "bison" in t:
                    cleaned = t.strip(",\"'")
                    names.append(cleaned)

        # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªÙØ¶ÙŠÙ„ Ù„Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆØ«ÙˆÙ‚ Ø¥Ù† ÙˆÙØ¬Ø¯
        preferred = ["models/gemini-1.5-flash", "models/gemini-1.5", "models/gemini-1.0", "models/text-bison-001", "bison", "gemini"]
        for p in preferred:
            for n in names:
                if p in n:
                    return n, raw_list

        # Ø¥Ù† Ù„Ù… Ù†Ø¬Ø¯ ØªÙØ¶ÙŠÙ„Ø§ØªØŒ Ù†ÙØ¹ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„ Ø¥Ù† ÙˆÙØ¬Ø¯
        if names:
            return names[0], raw_list

        return None, raw_list
    except Exception as e:
        return None, f"Error calling list_models: {e}"

# ----------------------------
# ÙˆØ§Ø¬Ù‡Ø© Ø¬Ø§Ù†Ø¨ÙŠØ©
# ----------------------------
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    api_key = st.text_input("Ù…ÙØªØ§Ø­ API (Ù„Ù† ÙŠÙØ®Ø²Ù†):", type="password")
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["ÙÙŠØ²ÙŠØ§Ø¡", "ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø£Ø­ÙŠØ§Ø¡", "Ø¹Ù„ÙˆÙ…"])
    grade = st.selectbox("Ø§Ù„ØµÙ:", ["11", "12"])
    semester = st.selectbox("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ:", ["Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ"])
    exam_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:", ["Ù‚ØµÙŠØ±", "ØªØ¬Ø±ÙŠØ¨ÙŠ/Ù†Ù‡Ø§Ø¦ÙŠ"])
    pages = st.text_input("Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª (Ù…Ø«Ù„Ø§Ù‹ 1-5):", "1-50")

# ----------------------------
# Ø§Ù„Ø¬Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ----------------------------
st.title(f"ğŸ” ØªØ¯Ù‚ÙŠÙ‚ Ø§Ø®ØªØ¨Ø§Ø± {subject} - Ø§Ù„ØµÙ {grade}")

c1, c2, c3 = st.columns(3)
with c1:
    f_test = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (PDF)", type="pdf")
with c2:
    f_policy = st.file_uploader("ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (PDF)", type="pdf")
with c3:
    f_book = st.file_uploader("ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ (PDF)", type="pdf")

if st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
    if not api_key:
        st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ API ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.")
    elif not f_test:
        st.error("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.")
    else:
        genai.configure(api_key=api_key)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆÙÙ‚ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±..."):
            t_test = extract_pdf_text(f_test)
            t_policy = extract_pdf_text(f_policy) if f_policy else ""
            t_book = extract_pdf_text(f_book) if f_book else ""

            # Ù„ØªØ¬Ù†Ø¨ Ø¥Ø±Ø³Ø§Ù„ Ù†ØµÙˆØµ Ø¶Ø®Ù…Ø© Ø¬Ø¯Ø§Ù‹ØŒ Ù†Ù‚ØªØµØ± Ø¹Ù„Ù‰ Ù…Ù‚ØªØ·ÙØ§Øª Ø£ÙˆÙ„ÙŠØ© â€” ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ max_chunk Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©
            max_chunk = 4000
            t_test_snip = t_test[:max_chunk]
            t_policy_snip = t_policy[:max_chunk]
            t_book_snip = t_book[:max_chunk]

            prompt = f"""
Ø­Ù„Ù„ Ø§Ø®ØªØ¨Ø§Ø± {subject} Ù„Ù„ØµÙ {grade} ÙØµÙ„ {semester}.
Ù‚Ø§Ø±Ù† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (Ø£Ø¯Ø®Ù„ Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¥Ù† ÙˆÙØ¬Ø¯Øª) ÙˆØ¨Ù…Ø­ØªÙˆÙ‰ ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨.
- ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (Ù…Ù‚ØªØ·Ù): {t_policy_snip}
- ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ (Ù…Ù‚ØªØ·Ù): ØµÙØ­Ø§Øª {pages} => {t_book_snip}
- Ù†Øµ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ù…Ù‚ØªØ·Ù): {t_test_snip}

Ø§Ø·Ø±Ø­ Ù…Ø®Ø±Ø¬Ø§Øª JSON ÙÙ‚Ø· Ø¨Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:
{{
  "vocab":[
    {{
      "q": "Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„",
      "obj": "Ø§Ù„Ù‡Ø¯Ù/Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚",
      "level": "AO1|AO2|AO3|...",
      "mark": 1,
      "note": "Ù…Ù„Ø§Ø­Ø¸Ø§Øª",
      "fix": "Ø§Ù‚ØªØ±Ø§Ø­ ØªØ¹Ø¯ÙŠÙ„"
    }}
  ],
  "specs": {{
    "q_count":{{"val": 0, "status": "OK|Missing"}},
    "lessons":{{"val":"Ù‚Ø§Ø¦Ù…Ø©","status":"Covered|Not covered"}},
    "ao1":{{"val":0,"status":"OK"}},
    "ao2":{{"val":0,"status":"OK"}},
    "clarity":{{"val":"High|Low","status":"OK|Needs revision"}}
  }},
  "summary":"Ù…Ù„Ø®Øµ ØªØ­Ù„ÙŠÙ„ÙŠ Ù‚ØµÙŠØ±"
}}
"""

            # Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø§Ø³Ø¨ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
            chosen_model, models_raw = choose_model_and_list()

            if not chosen_model:
                st.error("ØªØ¹Ø°Ø± Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ Ù…ØªØ§Ø­ Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© API Ø§Ù„Ù…Ø«Ø¨ØªØ©. Ø§Ù†Ø¸Ø± ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ø£Ø¯Ù†Ø§Ù‡.")
                st.code(models_raw)
            else:
                # Ù†Ø¹Ø±Ø¶ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ Ø³Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
                st.info(f"Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {chosen_model}")

                raw_text = None
                gen_error = None
                try:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø³Ù„ÙˆØ¨ Ù‚Ø¯ÙŠÙ… Ø¥Ù† Ø£Ù…ÙƒÙ† (caching for compatibility)
                    try:
                        # Ø¨Ø¹Ø¶ Ø§Ù„Ù†Ø³Ø® Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªÙˆÙØ± Ù…ÙˆÙ„Ø¯ Ù†Ù…ÙˆØ°Ø¬ ÙƒÙƒÙ„Ø§Ø³
                        model_obj = None
                        if hasattr(genai, "GenerativeModel"):
                            try:
                                model_obj = genai.GenerativeModel(chosen_model)
                            except Exception:
                                model_obj = None
                        if model_obj is not None and hasattr(model_obj, "generate_content"):
                            res = model_obj.generate_content(prompt)
                            raw_text = getattr(res, "text", None) or getattr(res, "content", None) or str(res)
                        else:
                            raise AttributeError("model_obj.generate_content not available - falling back")
                    except Exception:
                        # Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ø¬Ù‡Ø© genai.generate_text (Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø¨Ø¹Ø¶ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ¨Ø©)
                        try:
                            if hasattr(genai, "generate_text"):
                                res = genai.generate_text(model=chosen_model, prompt=prompt)
                                # Ø´ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù‚Ø¯ ÙŠØ®ØªÙ„Ù Ø­Ø³Ø¨ Ø§Ù„Ù†Ø³Ø®Ø©
                                raw_text = getattr(res, "text", None) or getattr(res, "content", None) or getattr(res, "output", None) or str(res)
                            else:
                                raise AttributeError("genai.generate_text not available")
                        except Exception:
                            # Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ø¬Ù‡Ø© Ø¹Ø§Ù…Ø© genai.generate Ø¥Ù† ÙˆÙØ¬Ø¯Øª
                            if hasattr(genai, "generate"):
                                res = genai.generate(model=chosen_model, prompt=prompt)
                                raw_text = getattr(res, "text", None) or getattr(res, "content", None) or getattr(res, "output", None) or str(res)
                            else:
                                raise RuntimeError("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù„Ù„ØªÙˆÙ„ÙŠØ¯ ÙÙŠ Ù…ÙƒØªØ¨Ø© google-generativeai Ø§Ù„Ù…Ø«Ø¨ØªØ©.")

                    # ØªÙ†Ø¸ÙŠÙ ÙˆØ¥ÙŠØ¬Ø§Ø¯ JSON
                    if not raw_text:
                        raise RuntimeError("Ø§Ù„Ù…ÙˆÙ„Ø¯ Ø£Ø¹Ø§Ø¯ Ù†ØªÙŠØ¬Ø© ÙØ§Ø±ØºØ©.")

                    cleaned = raw_text.replace("```json", "").replace("```", "").strip()
                    start = cleaned.find("{")
                    end = cleaned.rfind("}")
                    if start == -1 or end == -1:
                        raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ JSON ØµØ§Ù„Ø­ ÙÙŠ Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
                    js_str = cleaned[start:end+1]
                    data = json.loads(js_str)

                    st.success("Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

                    # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª (Ø¬Ø¯ÙˆÙ„ HTML Ø¨Ø³ÙŠØ·)
                    st.subheader("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª")
                    vocab = data.get("vocab", [])
                    if vocab:
                        rows = "".join([f"<tr><td>{i.get('q','')}</td><td>{i.get('obj','')}</td><td>{i.get('level','')}</td><td>{i.get('mark','')}</td><td>{i.get('note','')}</td><td>{i.get('fix','')}</td></tr>" for i in vocab])
                        st.markdown(f"<table><tr><th>Ù…</th><th>Ø§Ù„Ù‡Ø¯Ù</th><th>Ø§Ù„Ù…Ø³ØªÙˆÙ‰</th><th>Ø§Ù„Ø¯Ø±Ø¬Ø©</th><th>Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©</th><th>Ø§Ù„ØªØ¹Ø¯ÙŠÙ„</th></tr>{rows}</table>", unsafe_allow_html=True)
                    else:
                        st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙØ±Ø¯Ø§Øª Ù…ÙØ¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø©.")

                    # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„
                    st.subheader("Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„")
                    specs = data.get("specs", {})
                    mapping = {"q_count":"Ø§Ù„Ø¹Ø¯Ø¯","lessons":"Ø§Ù„Ø¯Ø±ÙˆØ³","ao1":"AO1","ao2":"AO2","clarity":"Ø§Ù„ÙˆØ¶ÙˆØ­"}
                    s_rows = ""
                    for k, lbl in mapping.items():
                        val = specs.get(k, {}).get("val", "-")
                        status = specs.get(k, {}).get("status", "-")
                        s_rows += f"<tr><td>{lbl}</td><td>{val}</td><td>{status}</td></tr>"
                    st.markdown(f"<table><tr><th>Ø§Ù„Ø¨Ù†Ø¯</th><th>Ø§Ù„Ù‚ÙŠÙ…Ø©</th><th>Ø§Ù„Ø­Ø§Ù„Ø©</th></tr>{s_rows}</table>", unsafe_allow_html=True)

                    st.info(data.get("summary", ""))

                    st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Word)", generate_word(data, subject, grade, semester, exam_type), "Report.docx")

                except Exception as gen_exc:
                    # Ù„Ø§ Ù†Ø¹Ø±Ø¶ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€API Ø£Ø¨Ø¯Ø§Ù‹Ø› Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
                    gen_error = str(gen_exc)
                    st.error("ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ â€” Ø±Ø§Ø¬Ø¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø£Ø¯Ù†Ø§Ù‡.")
                    st.markdown(f"<div class='error-box'>Ø®Ø·Ø£ Ø§Ù„ØªÙ†ÙÙŠØ°: {gen_error}</div>", unsafe_allow_html=True)
                    # Ù†Ø¹Ø±Ø¶ Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ø§Ù… Ø¥Ù† ÙˆÙØ¬Ø¯Øª Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ
                    if raw_text:
                        st.subheader("Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø®Ø§Ù…)")
                        st.code(raw_text)
                    # Ù†Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø®Ø§Ù… Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¹Ù„Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ø³Ù… Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯Ø¹Ù…Ù‡ Ø­Ø³Ø§Ø¨Ùƒ/Ø§Ù„Ù…ÙƒØªØ¨Ø©
                    st.subheader("Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ´Ø®ÙŠØµ)")
                    st.code(models_raw)

                    # Ø§Ø­ØªÙŠØ§Ø·ÙŠ: Ù„ÙˆØ¬ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù„ÙˆØ­Ø© (Ù„Ù„Ù…Ø·ÙˆØ± ÙÙ‚Ø·ØŒ Ù„ÙƒÙ† Ù„ÙŠØ³ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€API)
                    st.subheader("ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ (traceback)")
                    st.code(traceback.format_exc())
