import streamlit as st
import fitz  # PyMuPDF
import google.generativeai as genai
import json
import re
from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from io import BytesIO

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
# ==========================================
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„ØªØ±Ø¨ÙˆÙŠ Ø§Ù„Ø¹Ù…Ø§Ù†ÙŠ", layout="wide")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    div[data-testid="stSidebar"] { text-align: right; direction: rtl; }
    div[data-testid="stMarkdownContainer"] { text-align: right; direction: rtl; }
    .header-box { background: #f0f8ff; padding: 20px; border-radius: 10px; border-right: 8px solid #007bff; margin-bottom: 20px; }
    table { width: 100%; direction: rtl; border-collapse: collapse; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: right; }
    th { background-color: #f2f2f2; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (PDF Ùˆ Word)
# ==========================================

def extract_text_from_pdf(uploaded_file):
    if not uploaded_file: return ""
    try:
        doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
        text = "".join([page.get_text() for page in doc])
        return text
    except Exception as e:
        return ""

def create_word_docx(report_data, subject, grade, semester, exam_type):
    doc = Document()
    
    # Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    title = doc.add_heading(f'ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ {exam_type} - Ù…Ø§Ø¯Ø© {subject}', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    p = doc.add_paragraph(f'Ø§Ù„ØµÙ: {grade} | Ø§Ù„ÙØµÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ: {semester}')
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph('--------------------------------------------------------')

    # Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø±Ø³Ù… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ø§Ù„ÙˆÙˆØ±Ø¯
    def add_table_to_doc(headers, rows):
        table = doc.add_table(rows=1, cols=len(headers))
        table.style = 'Table Grid'
        table.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        # ØªØ±ÙˆÙŠØ³Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
        hdr_cells = table.rows[0].cells
        for i, h in enumerate(headers):
            hdr_cells[i].text = h
            hdr_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.RIGHT
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for row_data in rows:
            row_cells = table.add_row().cells
            for i, item in enumerate(row_data):
                row_cells[i].text = str(item)
                row_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.RIGHT
        doc.add_paragraph('')

    # 1. Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
    doc.add_heading('1. Ø¬Ø¯ÙˆÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†ÙŠØ©', level=1)
    vocab_headers = ["Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„", "Ø§Ù„Ù‡Ø¯Ù", "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ (AO1/AO2)", "Ø§Ù„Ø¯Ø±Ø¬Ø©", "Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©", "Ø§Ù„ØªØ¹Ø¯ÙŠÙ„"]
    vocab_rows = []
    if "vocab_table" in report_data:
        for item in report_data["vocab_table"]:
            vocab_rows.append([
                item.get("q_num", ""),
                item.get("objective", ""),
                item.get("level", ""),
                item.get("marks", ""),
                item.get("note", ""),
                item.get("fix", "")
            ])
        add_table_to_doc(vocab_headers, vocab_rows)

    # 2. Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„
    doc.add_heading('2. Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„ (Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„ÙÙ†ÙŠØ©)', level=1)
    working_headers = ["Ø§Ù„Ø¨Ù†Ø¯", "Ø§Ù„Ù‚ÙŠÙ…Ø© / Ø§Ù„Ø¹Ø¯Ø¯", "Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"]
    working_rows = []
    if "working_table" in report_data:
        wt = report_data["working_table"]
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¹Ù†Ø§ØµØ±
        keys_order = ["total_questions", "lessons_count", "ao1_marks", "ao2_marks", "mcq_distractors", "clarity"]
        labels = {
            "total_questions": "Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª", "lessons_count": "Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ø±ÙˆØ³", 
            "ao1_marks": "Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ© (AO1)", "ao2_marks": "Ø¯Ø±Ø¬Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (AO2)",
            "mcq_distractors": "Ø§Ù„Ù…Ø´ØªØªØ§Øª (MCQ)", "clarity": "Ø¬ÙˆØ¯Ø© Ø§Ù„Ø±Ø³ÙˆÙ… ÙˆØ§Ù„Ø®Ø·"
        }
        for k in keys_order:
            val = wt.get(k, {})
            working_rows.append([labels.get(k, k), val.get("value", "-"), val.get("status", "-")])
        add_table_to_doc(working_headers, working_rows)

    # 3. Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù…
    doc.add_heading('3. Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù…', level=1)
    if "summary" in report_data:
        p = doc.add_paragraph(report_data["summary"])
        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Sidebar) - Ù…Ø¹Ø¯Ù„Ø© Ø­Ø³Ø¨ Ø·Ù„Ø¨Ùƒ
# ==========================================

with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚")
    api_key = st.text_input("Ù…ÙØªØ§Ø­ API:", type="password")
    
    # 1. Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·
    subject = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø©:", ["ÙÙŠØ²ÙŠØ§Ø¡", "ÙƒÙŠÙ…ÙŠØ§Ø¡", "Ø£Ø­ÙŠØ§Ø¡", "Ø¹Ù„ÙˆÙ…"])
    
    # 2. Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·
    grade = st.selectbox("Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØµÙÙŠØ©:", ["11", "12"])
    
    # 3. Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„ÙØµÙ„ ÙˆÙ†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù„Ø¯Ù‚Ø©)
    semester = st.selectbox("Ø§Ù„ÙØµÙ„ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ:", ["Ø§Ù„Ø£ÙˆÙ„", "Ø§Ù„Ø«Ø§Ù†ÙŠ"])
    exam_type = st.selectbox("Ù†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:", ["Ù‚ØµÙŠØ±", "ØªØ¬Ø±ÙŠØ¨ÙŠ/Ù†Ù‡Ø§Ø¦ÙŠ"])
    
    pages = st.text_input("Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª Ù„Ù„ÙƒØªØ§Ø¨:", "Ù…Ø«Ù„Ø§Ù‹: 20-45")

# ==========================================
# 4. Ø§Ù„Ø¬Ø³Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
# ==========================================

st.markdown(f'<div class="header-box"><h2>ğŸ‡´ğŸ‡² Ù†Ø¸Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª {subject} (Ø§Ù„ØµÙ {grade})</h2><p>Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± + ØªØµØ¯ÙŠØ± Ù…Ù„Ù Word</p></div>', unsafe_allow_html=True)

col1, col2, col3 = st.columns(3)
with col1: t_file = st.file_uploader("1. Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (PDF)", type="pdf")
with col2: p_file = st.file_uploader("2. ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªÙ‚ÙˆÙŠÙ… (PDF)", type="pdf")
with col3: b_file = st.file_uploader("3. ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ø§Ù„Ø¨ (PDF)", type="pdf")

if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ù…ÙŠ") and api_key and t_file:
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª..."):
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ
            txt_test = extract_text_from_pdf(t_file)
            txt_book = extract_text_from_pdf(b_file)
            txt_policy = extract_text_from_pdf(p_file)
            
            # Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Prompt)
            prompt = f"""
            Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªÙ‚ÙˆÙŠÙ… ØªØ±Ø¨ÙˆÙŠ ÙÙŠ Ø³Ù„Ø·Ù†Ø© Ø¹Ù…Ø§Ù†. Ø­Ù„Ù„ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø§Ø¯Ø© {subject} Ù„Ù„ØµÙ {grade} Ø§Ù„ÙØµÙ„ {semester}.
            
            Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØµÙŠØºØ© JSON Ø­ØµØ±Ø§Ù‹ Ù„Ù…Ù„Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ©.

            Ù‡ÙŠÙƒÙ„ JSON Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
            {{
                "vocab_table": [
                    {{ "q_num": "1", "objective": "Ø§Ù„Ù‡Ø¯Ù", "level": "AO1", "marks": "1", "note": "Ù…Ù„Ø§Ø­Ø¸Ø©", "fix": "ØªØ¹Ø¯ÙŠÙ„" }}
                ],
                "working_table": {{
                    "total_questions": {{ "value": "Ø§Ù„Ø¹Ø¯Ø¯", "status": "Ù…Ù†Ø§Ø³Ø¨/ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨" }},
                    "lessons_count": {{ "value": "Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ", "status": "-" }},
                    "ao1_marks": {{ "value": "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹", "status": "-" }},
                    "ao2_marks": {{ "value": "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹", "status": "-" }},
                    "mcq_distractors": {{ "value": "ÙˆØµÙ Ø§Ù„Ù…Ø´ØªØªØ§Øª", "status": "Ø¬ÙŠØ¯/Ø¶Ø¹ÙŠÙ" }},
                    "clarity": {{ "value": "ÙˆØµÙ Ø§Ù„Ø®Ø· ÙˆØ§Ù„Ø±Ø³ÙˆÙ…", "status": "ÙˆØ§Ø¶Ø­/ØºÙŠØ± ÙˆØ§Ø¶Ø­" }}
                }},
                "summary": "Ù†Øµ Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù… ÙˆÙ†Ø³Ø¨Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©."
            }}

            Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
            Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {txt_test[:15000]}
            Ø§Ù„ÙƒØªØ§Ø¨ (Ù†Ø·Ø§Ù‚ {pages}): {txt_book[:15000]}
            Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©: {txt_policy[:5000]}
            """

            response = model.generate_content(prompt)
            
            # ØªÙ†Ø¸ÙŠÙ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON
            text_resp = response.text
            json_str = text_resp.replace("```json", "").replace("```", "").strip()
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ø³Ø±ÙŠØ¹Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„Ù‚ÙˆØ³
            if "{" in json_str:
                json_str = json_str[json_str.find("{"):json_str.rfind("}")+1]

            try:
                data = json.loads(json_str)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹
                st.success("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„Ø£Ø³ÙÙ„ ğŸ‘‡")
                
                # 1. Ø¹Ø±Ø¶ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
                st.subheader("1. Ø¬Ø¯ÙˆÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª")
                v_rows = ""
                for r in data.get("vocab_table", []):
                    v_rows += f"<tr><td>{r.get('q_num')}</td><td>{r.get('objective')}</td><td>{r.get('level')}</td><td>{r.get('marks')}</td><td>{r.get('note')}</td><td>{r.get('fix')}</td></tr>"
                st.markdown(f"<table><tr><th>Ø³</th><th>Ø§Ù„Ù‡Ø¯Ù</th><th>Ø§Ù„Ù…Ø³ØªÙˆÙ‰</th><th>Ø§Ù„Ø¯Ø±Ø¬Ø©</th><th>Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©</th><th>Ø§Ù„ØªØ¹Ø¯ÙŠÙ„</th></tr>{v_rows}</table>", unsafe_allow_html=True)

                # 2. Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„
                st.subheader("2. Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…Ù„")
                w_rows = ""
                wt = data.get("working_table", {})
                labels = {"total_questions": "Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", "lessons_count": "Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ø±ÙˆØ³", "ao1_marks": "Ù…Ø¬Ù…ÙˆØ¹ AO1", "ao2_marks": "Ù…Ø¬Ù…ÙˆØ¹ AO2", "mcq_distractors": "Ø§Ù„Ù…Ø´ØªØªØ§Øª", "clarity": "Ø§Ù„ÙˆØ¶ÙˆØ­"}
                for k, v in labels.items():
                    item = wt.get(k, {})
                    w_rows += f"<tr><td>{v}</td><td>{item.get('value')}</td><td>{item.get('status')}</td></tr>"
                st.markdown(f"<table><tr><th>Ø§Ù„Ø¨Ù†Ø¯</th><th>Ø§Ù„Ù‚ÙŠÙ…Ø©</th><th>Ø§Ù„Ø­Ø§Ù„Ø©</th></tr>{w_rows}</table>", unsafe_allow_html=True)

                # 3. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ø®Øµ
                st.subheader("3. Ø§Ù„ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù…")
                st.info(data.get("summary"))

                # 4. Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„ (Word)
                docx = create_word_docx(data, subject, grade, semester, exam_type)
                st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Word)", docx, "Report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")

            except Exception as e:
                st.warning("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯ÙˆÙ„ØŒ Ù„ÙƒÙ† Ø¥Ù„ÙŠÙƒ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„ØªØ­Ù„ÙŠÙ„:")
                st.markdown(response.text)

    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
